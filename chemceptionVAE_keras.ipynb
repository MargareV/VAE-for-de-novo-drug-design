{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "chemceptionVAE_keras.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MargareV/VAE-for-de-novo-drug-design/blob/master/chemceptionVAE_keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C76wJaPbgJZv",
        "colab_type": "code",
        "outputId": "603cd903-25b5-49ed-cd45-46040d4a848e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwV2ug9kgZ6r",
        "colab_type": "code",
        "outputId": "e8f07503-9da5-470b-f5c7-e40cdf85453b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!wget -c https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
        "!chmod +x Miniconda3-latest-Linux-x86_64.sh\n",
        "!time bash ./Miniconda3-latest-Linux-x86_64.sh -b -f -p /usr/local\n",
        "!time conda install -q -y -c conda-forge rdkit"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2019-11-29 14:21:02--  https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.sh\n",
            "Resolving repo.continuum.io (repo.continuum.io)... 104.18.200.79, 104.18.201.79, 2606:4700::6812:c84f, ...\n",
            "Connecting to repo.continuum.io (repo.continuum.io)|104.18.200.79|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71785000 (68M) [application/x-sh]\n",
            "Saving to: ‘Miniconda3-latest-Linux-x86_64.sh’\n",
            "\n",
            "\r          Miniconda   0%[                    ]       0  --.-KB/s               \r         Miniconda3  41%[=======>            ]  28.45M   142MB/s               \r        Miniconda3-  86%[================>   ]  59.33M   148MB/s               \rMiniconda3-latest-L 100%[===================>]  68.46M   142MB/s    in 0.5s    \n",
            "\n",
            "2019-11-29 14:21:03 (142 MB/s) - ‘Miniconda3-latest-Linux-x86_64.sh’ saved [71785000/71785000]\n",
            "\n",
            "PREFIX=/usr/local\n",
            "Unpacking payload ...\n",
            "Collecting package metadata (current_repodata.json): - \b\b\\ \b\bdone\n",
            "Solving environment: / \b\b- \b\bdone\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - _libgcc_mutex==0.1=main\n",
            "    - asn1crypto==1.2.0=py37_0\n",
            "    - ca-certificates==2019.10.16=0\n",
            "    - certifi==2019.9.11=py37_0\n",
            "    - cffi==1.13.0=py37h2e261b9_0\n",
            "    - chardet==3.0.4=py37_1003\n",
            "    - conda-package-handling==1.6.0=py37h7b6447c_0\n",
            "    - conda==4.7.12=py37_0\n",
            "    - cryptography==2.8=py37h1ba5d50_0\n",
            "    - idna==2.8=py37_0\n",
            "    - libedit==3.1.20181209=hc058e9b_0\n",
            "    - libffi==3.2.1=hd88cf55_4\n",
            "    - libgcc-ng==9.1.0=hdf63c60_0\n",
            "    - libstdcxx-ng==9.1.0=hdf63c60_0\n",
            "    - ncurses==6.1=he6710b0_1\n",
            "    - openssl==1.1.1d=h7b6447c_3\n",
            "    - pip==19.3.1=py37_0\n",
            "    - pycosat==0.6.3=py37h14c3975_0\n",
            "    - pycparser==2.19=py37_0\n",
            "    - pyopenssl==19.0.0=py37_0\n",
            "    - pysocks==1.7.1=py37_0\n",
            "    - python==3.7.4=h265db76_1\n",
            "    - readline==7.0=h7b6447c_5\n",
            "    - requests==2.22.0=py37_0\n",
            "    - ruamel_yaml==0.15.46=py37h14c3975_0\n",
            "    - setuptools==41.4.0=py37_0\n",
            "    - six==1.12.0=py37_0\n",
            "    - sqlite==3.30.0=h7b6447c_0\n",
            "    - tk==8.6.8=hbc83047_0\n",
            "    - tqdm==4.36.1=py_0\n",
            "    - urllib3==1.24.2=py37_0\n",
            "    - wheel==0.33.6=py37_0\n",
            "    - xz==5.2.4=h14c3975_4\n",
            "    - yaml==0.1.7=had09818_2\n",
            "    - zlib==1.2.11=h7b6447c_3\n",
            "\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  _libgcc_mutex      pkgs/main/linux-64::_libgcc_mutex-0.1-main\n",
            "  asn1crypto         pkgs/main/linux-64::asn1crypto-1.2.0-py37_0\n",
            "  ca-certificates    pkgs/main/linux-64::ca-certificates-2019.10.16-0\n",
            "  certifi            pkgs/main/linux-64::certifi-2019.9.11-py37_0\n",
            "  cffi               pkgs/main/linux-64::cffi-1.13.0-py37h2e261b9_0\n",
            "  chardet            pkgs/main/linux-64::chardet-3.0.4-py37_1003\n",
            "  conda              pkgs/main/linux-64::conda-4.7.12-py37_0\n",
            "  conda-package-han~ pkgs/main/linux-64::conda-package-handling-1.6.0-py37h7b6447c_0\n",
            "  cryptography       pkgs/main/linux-64::cryptography-2.8-py37h1ba5d50_0\n",
            "  idna               pkgs/main/linux-64::idna-2.8-py37_0\n",
            "  libedit            pkgs/main/linux-64::libedit-3.1.20181209-hc058e9b_0\n",
            "  libffi             pkgs/main/linux-64::libffi-3.2.1-hd88cf55_4\n",
            "  libgcc-ng          pkgs/main/linux-64::libgcc-ng-9.1.0-hdf63c60_0\n",
            "  libstdcxx-ng       pkgs/main/linux-64::libstdcxx-ng-9.1.0-hdf63c60_0\n",
            "  ncurses            pkgs/main/linux-64::ncurses-6.1-he6710b0_1\n",
            "  openssl            pkgs/main/linux-64::openssl-1.1.1d-h7b6447c_3\n",
            "  pip                pkgs/main/linux-64::pip-19.3.1-py37_0\n",
            "  pycosat            pkgs/main/linux-64::pycosat-0.6.3-py37h14c3975_0\n",
            "  pycparser          pkgs/main/linux-64::pycparser-2.19-py37_0\n",
            "  pyopenssl          pkgs/main/linux-64::pyopenssl-19.0.0-py37_0\n",
            "  pysocks            pkgs/main/linux-64::pysocks-1.7.1-py37_0\n",
            "  python             pkgs/main/linux-64::python-3.7.4-h265db76_1\n",
            "  readline           pkgs/main/linux-64::readline-7.0-h7b6447c_5\n",
            "  requests           pkgs/main/linux-64::requests-2.22.0-py37_0\n",
            "  ruamel_yaml        pkgs/main/linux-64::ruamel_yaml-0.15.46-py37h14c3975_0\n",
            "  setuptools         pkgs/main/linux-64::setuptools-41.4.0-py37_0\n",
            "  six                pkgs/main/linux-64::six-1.12.0-py37_0\n",
            "  sqlite             pkgs/main/linux-64::sqlite-3.30.0-h7b6447c_0\n",
            "  tk                 pkgs/main/linux-64::tk-8.6.8-hbc83047_0\n",
            "  tqdm               pkgs/main/noarch::tqdm-4.36.1-py_0\n",
            "  urllib3            pkgs/main/linux-64::urllib3-1.24.2-py37_0\n",
            "  wheel              pkgs/main/linux-64::wheel-0.33.6-py37_0\n",
            "  xz                 pkgs/main/linux-64::xz-5.2.4-h14c3975_4\n",
            "  yaml               pkgs/main/linux-64::yaml-0.1.7-had09818_2\n",
            "  zlib               pkgs/main/linux-64::zlib-1.2.11-h7b6447c_3\n",
            "\n",
            "\n",
            "Preparing transaction: | \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "Executing transaction: / \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\b| \b\b/ \b\b- \b\b\\ \b\bdone\n",
            "installation finished.\n",
            "WARNING:\n",
            "    You currently have a PYTHONPATH environment variable set. This may cause\n",
            "    unexpected behavior when running the Python interpreter in Miniconda3.\n",
            "    For best results, please verify that your PYTHONPATH only points to\n",
            "    directories of packages that are compatible with the Python interpreter\n",
            "    in Miniconda3: /usr/local\n",
            "\n",
            "real\t0m17.160s\n",
            "user\t0m9.153s\n",
            "sys\t0m3.932s\n",
            "Collecting package metadata (current_repodata.json): ...working... done\n",
            "Solving environment: ...working... done\n",
            "\n",
            "## Package Plan ##\n",
            "\n",
            "  environment location: /usr/local\n",
            "\n",
            "  added / updated specs:\n",
            "    - rdkit\n",
            "\n",
            "\n",
            "The following packages will be downloaded:\n",
            "\n",
            "    package                    |            build\n",
            "    ---------------------------|-----------------\n",
            "    boost-1.70.0               |   py37h9de70de_1         337 KB  conda-forge\n",
            "    boost-cpp-1.70.0           |       h8e57a91_2        21.1 MB  conda-forge\n",
            "    bzip2-1.0.8                |       h516909a_1         397 KB  conda-forge\n",
            "    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n",
            "    cairo-1.16.0               |    hfb77d84_1002         1.5 MB  conda-forge\n",
            "    certifi-2019.11.28         |           py37_0         148 KB  conda-forge\n",
            "    conda-4.7.12               |           py37_0         3.0 MB  conda-forge\n",
            "    fontconfig-2.13.1          |    h86ecdb6_1001         340 KB  conda-forge\n",
            "    freetype-2.10.0            |       he983fc9_1         884 KB  conda-forge\n",
            "    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n",
            "    glib-2.58.3                |py37h6f030ca_1002         3.3 MB  conda-forge\n",
            "    icu-64.2                   |       he1b5a44_1        12.6 MB  conda-forge\n",
            "    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n",
            "    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n",
            "    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n",
            "    libgfortran-ng-7.3.0       |       hdf63c60_2         1.7 MB  conda-forge\n",
            "    libiconv-1.15              |    h516909a_1005         2.0 MB  conda-forge\n",
            "    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n",
            "    libopenblas-0.3.7          |       h6e990d7_3         7.6 MB  conda-forge\n",
            "    libpng-1.6.37              |       hed695b0_0         343 KB  conda-forge\n",
            "    libtiff-4.1.0              |       hc3755c2_1         609 KB  conda-forge\n",
            "    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n",
            "    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n",
            "    libxml2-2.9.10             |       hee79883_0         1.3 MB  conda-forge\n",
            "    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n",
            "    numpy-1.17.3               |   py37h95a1406_0         5.1 MB  conda-forge\n",
            "    olefile-0.46               |             py_0          31 KB  conda-forge\n",
            "    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n",
            "    pandas-0.25.3              |   py37hb3f55d8_0        11.4 MB  conda-forge\n",
            "    pcre-8.43                  |       he1b5a44_0         257 KB  conda-forge\n",
            "    pillow-6.2.1               |   py37h34e0f95_0         643 KB\n",
            "    pixman-0.38.0              |    h516909a_1003         594 KB  conda-forge\n",
            "    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n",
            "    pycairo-1.18.2             |   py37h438ddbb_0          77 KB  conda-forge\n",
            "    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n",
            "    pytz-2019.3                |             py_0         237 KB  conda-forge\n",
            "    rdkit-2019.09.1            |   py37hb31dc5d_0        23.8 MB  conda-forge\n",
            "    xorg-kbproto-1.0.7         |    h14c3975_1002          26 KB  conda-forge\n",
            "    xorg-libice-1.0.10         |       h516909a_0          57 KB  conda-forge\n",
            "    xorg-libsm-1.2.3           |    h84519dc_1000          25 KB  conda-forge\n",
            "    xorg-libx11-1.6.9          |       h516909a_0         918 KB  conda-forge\n",
            "    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n",
            "    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n",
            "    xorg-libxext-1.3.4         |       h516909a_0          51 KB  conda-forge\n",
            "    xorg-libxrender-0.9.10     |    h516909a_1002          31 KB  conda-forge\n",
            "    xorg-renderproto-0.11.1    |    h14c3975_1002           8 KB  conda-forge\n",
            "    xorg-xextproto-7.3.0       |    h14c3975_1002          27 KB  conda-forge\n",
            "    xorg-xproto-7.0.31         |    h14c3975_1007          72 KB  conda-forge\n",
            "    zstd-1.4.4                 |       h3b9ef0a_1         989 KB  conda-forge\n",
            "    ------------------------------------------------------------\n",
            "                                           Total:       108.3 MB\n",
            "\n",
            "The following NEW packages will be INSTALLED:\n",
            "\n",
            "  boost              conda-forge/linux-64::boost-1.70.0-py37h9de70de_1\n",
            "  boost-cpp          conda-forge/linux-64::boost-cpp-1.70.0-h8e57a91_2\n",
            "  bzip2              conda-forge/linux-64::bzip2-1.0.8-h516909a_1\n",
            "  cairo              conda-forge/linux-64::cairo-1.16.0-hfb77d84_1002\n",
            "  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-h86ecdb6_1001\n",
            "  freetype           conda-forge/linux-64::freetype-2.10.0-he983fc9_1\n",
            "  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n",
            "  glib               conda-forge/linux-64::glib-2.58.3-py37h6f030ca_1002\n",
            "  icu                conda-forge/linux-64::icu-64.2-he1b5a44_1\n",
            "  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001\n",
            "  libblas            conda-forge/linux-64::libblas-3.8.0-14_openblas\n",
            "  libcblas           conda-forge/linux-64::libcblas-3.8.0-14_openblas\n",
            "  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.3.0-hdf63c60_2\n",
            "  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1005\n",
            "  liblapack          conda-forge/linux-64::liblapack-3.8.0-14_openblas\n",
            "  libopenblas        conda-forge/linux-64::libopenblas-0.3.7-h6e990d7_3\n",
            "  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_0\n",
            "  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc3755c2_1\n",
            "  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n",
            "  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n",
            "  libxml2            conda-forge/linux-64::libxml2-2.9.10-hee79883_0\n",
            "  lz4-c              conda-forge/linux-64::lz4-c-1.8.3-he1b5a44_1001\n",
            "  numpy              conda-forge/linux-64::numpy-1.17.3-py37h95a1406_0\n",
            "  olefile            conda-forge/noarch::olefile-0.46-py_0\n",
            "  pandas             conda-forge/linux-64::pandas-0.25.3-py37hb3f55d8_0\n",
            "  pcre               conda-forge/linux-64::pcre-8.43-he1b5a44_0\n",
            "  pillow             pkgs/main/linux-64::pillow-6.2.1-py37h34e0f95_0\n",
            "  pixman             conda-forge/linux-64::pixman-0.38.0-h516909a_1003\n",
            "  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n",
            "  pycairo            conda-forge/linux-64::pycairo-1.18.2-py37h438ddbb_0\n",
            "  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n",
            "  pytz               conda-forge/noarch::pytz-2019.3-py_0\n",
            "  rdkit              conda-forge/linux-64::rdkit-2019.09.1-py37hb31dc5d_0\n",
            "  xorg-kbproto       conda-forge/linux-64::xorg-kbproto-1.0.7-h14c3975_1002\n",
            "  xorg-libice        conda-forge/linux-64::xorg-libice-1.0.10-h516909a_0\n",
            "  xorg-libsm         conda-forge/linux-64::xorg-libsm-1.2.3-h84519dc_1000\n",
            "  xorg-libx11        conda-forge/linux-64::xorg-libx11-1.6.9-h516909a_0\n",
            "  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n",
            "  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n",
            "  xorg-libxext       conda-forge/linux-64::xorg-libxext-1.3.4-h516909a_0\n",
            "  xorg-libxrender    conda-forge/linux-64::xorg-libxrender-0.9.10-h516909a_1002\n",
            "  xorg-renderproto   conda-forge/linux-64::xorg-renderproto-0.11.1-h14c3975_1002\n",
            "  xorg-xextproto     conda-forge/linux-64::xorg-xextproto-7.3.0-h14c3975_1002\n",
            "  xorg-xproto        conda-forge/linux-64::xorg-xproto-7.0.31-h14c3975_1007\n",
            "  zstd               conda-forge/linux-64::zstd-1.4.4-h3b9ef0a_1\n",
            "\n",
            "The following packages will be UPDATED:\n",
            "\n",
            "  ca-certificates    pkgs/main::ca-certificates-2019.10.16~ --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n",
            "  certifi               pkgs/main::certifi-2019.9.11-py37_0 --> conda-forge::certifi-2019.11.28-py37_0\n",
            "\n",
            "The following packages will be SUPERSEDED by a higher-priority channel:\n",
            "\n",
            "  conda                                           pkgs/main --> conda-forge\n",
            "  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_3 --> conda-forge::openssl-1.1.1d-h516909a_0\n",
            "\n",
            "\n",
            "Preparing transaction: ...working... done\n",
            "Verifying transaction: ...working... done\n",
            "Executing transaction: ...working... done\n",
            "\n",
            "real\t0m44.839s\n",
            "user\t0m37.539s\n",
            "sys\t0m4.685s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6A5Hw50AVW1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4d45a713-feca-4efb-fbed-dceed8dd372e"
      },
      "source": [
        "!pip install tensorflow --upgrade"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2a/5c/f1d66de5dde6f3ff528f6ea1fd0757a0e594d17debb3ec7f82daa967ea9a/tensorflow-2.0.0-cp37-cp37m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 117kB/s \n",
            "\u001b[?25hCollecting google-pasta>=0.1.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.2MB/s \n",
            "\u001b[?25hCollecting wrapt>=1.11.1\n",
            "  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.7/site-packages (from tensorflow) (0.33.6)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.7MB/s \n",
            "\u001b[?25hCollecting absl-py>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 47.0MB/s \n",
            "\u001b[?25hCollecting protobuf>=3.6.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/82/c0/371cf368e2d8b1b7bcf9f9bafd7cec962487e654ad8296d8e0ad62011537/protobuf-3.11.0-cp37-cp37m-manylinux1_x86_64.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 40.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.12.0)\n",
            "Collecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 26.7MB/s \n",
            "\u001b[?25hCollecting grpcio>=1.8.6\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/68/070ee7609b452e950bd5af35f7161f0ceb0abd61cf16ff3b23c852d4594b/grpcio-1.25.0-cp37-cp37m-manylinux2010_x86_64.whl (2.4MB)\n",
            "\u001b[K     |████████████████████████████████| 2.4MB 39.5MB/s \n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/83/755bd5324777875e9dff19c2e59daec837d0378c09196634524a3d7269ac/opt_einsum-3.1.0.tar.gz (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 9.3MB/s \n",
            "\u001b[?25hCollecting termcolor>=1.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\n",
            "Collecting keras-preprocessing>=1.0.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 7.3MB/s \n",
            "\u001b[?25hCollecting astor>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/4f/950dfae467b384fc96bc6469de25d832534f6b4441033c39f914efd13418/astor-0.8.0-py2.py3-none-any.whl\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 40.9MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/site-packages (from tensorflow) (1.17.3)\n",
            "Collecting h5py\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/c0/abde58b837e066bca19a3f7332d9d0493521d7dd6b48248451a9e3fe2214/h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 41.0MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.7/site-packages (from protobuf>=3.6.1->tensorflow) (41.4.0)\n",
            "Collecting google-auth<2,>=1.6.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7b/cb/786dc53d93494784935a62947643b48250b84a882474e714f9af5e1a1928/google_auth-1.7.1-py2.py3-none-any.whl (74kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 10.5MB/s \n",
            "\u001b[?25hCollecting werkzeug>=0.11.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n",
            "\u001b[K     |████████████████████████████████| 327kB 42.2MB/s \n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading https://files.pythonhosted.org/packages/7b/b8/88def36e74bee9fce511c9519571f4e485e890093ab7442284f4ffaef60b/google_auth_oauthlib-0.4.1-py2.py3-none-any.whl\n",
            "Collecting markdown>=2.6.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 9.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: requests<3,>=2.21.0 in /usr/local/lib/python3.7/site-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow) (2.22.0)\n",
            "Collecting rsa<4.1,>=3.1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/02/e5/38518af393f7c214357079ce67a317307936896e961e35450b70fad2a9cf/rsa-4.0-py2.py3-none-any.whl\n",
            "Collecting cachetools<3.2,>=2.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/2f/a6/30b0a0bef12283e83e58c1d6e7b5aabc7acfc4110df81a4471655d33e704/cachetools-3.1.1-py2.py3-none-any.whl\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/50/bb4cefca37da63a0c52218ba2cb1b1c36110d84dcbae8aa48cd67c5e95c2/pyasn1_modules-0.2.7-py2.py3-none-any.whl (131kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 45.0MB/s \n",
            "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
            "  Downloading https://files.pythonhosted.org/packages/a3/12/b92740d845ab62ea4edf04d2f4164d82532b5a0b03836d4d4e71c6f3d379/requests_oauthlib-1.3.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (1.24.2)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2019.11.28)\n",
            "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow) (2.8)\n",
            "Collecting pyasn1>=0.1.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/1e/a94a8d635fa3ce4cfc7f506003548d0a2447ae76fd5ca53932970fe3053f/pyasn1-0.4.8-py2.py3-none-any.whl (77kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 9.8MB/s \n",
            "\u001b[?25hCollecting oauthlib>=3.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/05/57/ce2e7a8fa7c0afb54a0581b14a65b56e62b5759dbc98e80627142b8a3704/oauthlib-3.1.0-py2.py3-none-any.whl (147kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 45.2MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: wrapt, gast, absl-py, opt-einsum, termcolor\n",
            "  Building wheel for wrapt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wrapt: filename=wrapt-1.11.2-cp37-cp37m-linux_x86_64.whl size=70687 sha256=39e5ce495d588ee992285f3f2012bf7172d4a9695822480348d25d18501adbe0\n",
            "  Stored in directory: /root/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp37-none-any.whl size=7540 sha256=6998490c0c66af85bb3fcfa993b0660597002989d7c319baef2cac38e7585811\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "  Building wheel for absl-py (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for absl-py: filename=absl_py-0.8.1-cp37-none-any.whl size=121167 sha256=b697d4dab54ff5a5a2ef57db88ad7931de56654a8b1045b2661d3da2061b8c73\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n",
            "  Building wheel for opt-einsum (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for opt-einsum: filename=opt_einsum-3.1.0-cp37-none-any.whl size=61682 sha256=f74d0934481f6852e340866d752f57fa4655d2372744535d29d96627e7fa7e88\n",
            "  Stored in directory: /root/.cache/pip/wheels/2c/b1/94/43d03e130b929aae7ba3f8d15cbd7bc0d1cb5bb38a5c721833\n",
            "  Building wheel for termcolor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for termcolor: filename=termcolor-1.1.0-cp37-none-any.whl size=4832 sha256=31416b47601593be5d46ec29283e48919e06d271fe77f905c5498fb425de4165\n",
            "  Stored in directory: /root/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n",
            "Successfully built wrapt gast absl-py opt-einsum termcolor\n",
            "Installing collected packages: google-pasta, wrapt, gast, h5py, keras-applications, absl-py, protobuf, tensorflow-estimator, grpcio, opt-einsum, termcolor, keras-preprocessing, astor, pyasn1, rsa, cachetools, pyasn1-modules, google-auth, werkzeug, oauthlib, requests-oauthlib, google-auth-oauthlib, markdown, tensorboard, tensorflow\n",
            "Successfully installed absl-py-0.8.1 astor-0.8.0 cachetools-3.1.1 gast-0.2.2 google-auth-1.7.1 google-auth-oauthlib-0.4.1 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 oauthlib-3.1.0 opt-einsum-3.1.0 protobuf-3.11.0 pyasn1-0.4.8 pyasn1-modules-0.2.7 requests-oauthlib-1.3.0 rsa-4.0 tensorboard-2.0.2 tensorflow-2.0.0 tensorflow-estimator-2.0.1 termcolor-1.1.0 werkzeug-0.16.0 wrapt-1.11.2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cachetools",
                  "pyasn1_modules",
                  "rsa"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tx-KQRKPgdaQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "32aa4ab4-25d5-47e6-e018-9a02ae237b34"
      },
      "source": [
        "%matplotlib inline\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/usr/local/lib/python3.7/site-packages/')\n",
        "import rdkit\n",
        "from rdkit import Chem\n",
        "from rdkit.Chem import AllChem\n",
        "import pandas as pd\n",
        "import keras\n",
        "#from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
        "#from keras.optimizers import Adam\n",
        "#from keras.preprocessing.image import ImageDataGenerator\n",
        "#from keras.callbacks import ReduceLROnPlateau\n",
        "from __future__ import print_function\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "from keras.layers import Input, Dense, Lambda, Flatten, Reshape, Layer, MaxPooling2D, GlobalMaxPooling2D\n",
        "from keras.layers import Conv2D, Conv2DTranspose\n",
        "from keras.models import Model, Sequential\n",
        "from keras import backend as K\n",
        "from keras import metrics\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from datetime import datetime"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7NFD1t5GghPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def chemcepterize_mol(mol, embed=20.0, res=0.5):\n",
        "    dims = int(embed*2/res)\n",
        "    cmol = Chem.Mol(mol.ToBinary())\n",
        "    cmol.ComputeGasteigerCharges()\n",
        "    AllChem.Compute2DCoords(cmol)\n",
        "    coords = cmol.GetConformer(0).GetPositions()\n",
        "    vect = np.zeros((dims,dims))\n",
        "    #Bonds first\n",
        "    for i,bond in enumerate(mol.GetBonds()):\n",
        "        bondorder = bond.GetBondTypeAsDouble()\n",
        "        bidx = bond.GetBeginAtomIdx()\n",
        "        eidx = bond.GetEndAtomIdx()\n",
        "        bcoords = coords[bidx]\n",
        "        ecoords = coords[eidx]\n",
        "        frac = np.linspace(0,1,int(1/res*2)) #\n",
        "        for f in frac:\n",
        "            c = (f*bcoords + (1-f)*ecoords)\n",
        "            idx = int(round((c[0] + embed)/res))\n",
        "            idy = int(round((c[1]+ embed)/res))\n",
        "            #Save in the vector first channel\n",
        "            vect[ idx , idy] = bondorder\n",
        "    for i,atom in enumerate(cmol.GetAtoms()):\n",
        "            idx = int(round((coords[i][0] + embed)/res))\n",
        "            idy = int(round((coords[i][1]+ embed)/res))\n",
        "            #Atomic number\n",
        "            vect[ idx , idy] = atom.GetAtomicNum()\n",
        "    #Atom Layers\n",
        "#    for i,atom in enumerate(cmol.GetAtoms()):\n",
        "#            idx = int(round((coords[i][0] + embed)/res))\n",
        "#            idy = int(round((coords[i][1]+ embed)/res))\n",
        "            #Atomic number\n",
        "#            vect[ idx , idy, 1] = 0\n",
        "            #Gasteiger Charges\n",
        "#            charge = atom.GetProp(\"_GasteigerCharge\")\n",
        "#            vect[ idx , idy, 2] = 0\n",
        "            #Hybridization\n",
        "#            hyptype = atom.GetHybridization().real\n",
        "#            vect[ idx , idy, 2] = hyptype\n",
        "    return vect"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0YZXoOXgm1A",
        "colab_type": "code",
        "outputId": "d42c121d-f21c-4202-d51b-821cc9277e22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "print(\"Keras: %s\"%keras.__version__)\n",
        "print(\"RDKit: %s\"%rdkit.__version__)\n",
        "\n",
        "data = pd.read_csv('/content/drive/My Drive/Images_zinc/smiles_zinc.csv', skip_blank_lines=True, nrows=25000, usecols=[0])\n",
        "data[\"mol\"] = data[\"smiles\"].apply(Chem.MolFromSmiles)\n",
        "print(data.shape)\n",
        "\n",
        "def vectorize(mol):\n",
        "    return chemcepterize_mol(mol, embed=20)\n",
        "data[\"molimage\"] = data[\"mol\"].apply(vectorize)\n",
        "print(data.shape)\n",
        "final_data = np.array(list(data[\"molimage\"]))\n",
        "print(final_data.shape)\n",
        "x_test = final_data[20000:25000, ]\n",
        "x_train = final_data[0:20000, ]\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Keras: 2.2.5\n",
            "RDKit: 2019.09.1\n",
            "(25000, 2)\n",
            "(25000, 3)\n",
            "(25000, 80, 80)\n",
            "(20000, 6400)\n",
            "(5000, 6400)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-EiVjk0nFXK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 8\n",
        "image_size = x_train.shape[1]\n",
        "original_dim = image_size\n",
        "intermediate_dim = 3200\n",
        "latent_dim = 15\n",
        "epochs = 150\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbJ2w-UKgpnD",
        "colab_type": "code",
        "outputId": "7b6df404-7a38-495c-9d97-7a8bed660e9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        }
      },
      "source": [
        "x = Input(batch_shape=(batch_size, original_dim))\n",
        "h = Dense(intermediate_dim, activation='relu')(x)\n",
        "z_mean = Dense(latent_dim)(h)\n",
        "z_log_sigma = Dense(latent_dim)(h)\n",
        "\n",
        "def sampling(args):\n",
        "    z_mean, z_log_sigma = args\n",
        "    epsilon = K.random_normal(shape=(batch_size, latent_dim)) # for random_normal, mean=0. and std=1.\n",
        "    return z_mean + K.exp(z_log_sigma) * epsilon\n",
        "\n",
        "# note that \"output_shape\" isn't necessary with the TensorFlow backend\n",
        "# so you could write `Lambda(sampling)([z_mean, z_log_sigma])`\n",
        "z = Lambda(sampling, output_shape=(latent_dim,))([z_mean, z_log_sigma])\n",
        "\n",
        "decoder_h = Dense(intermediate_dim, activation='relu')\n",
        "decoder_mean = Dense(original_dim, activation='sigmoid')\n",
        "h_decoded = decoder_h(z)\n",
        "x_decoded_mean = decoder_mean(h_decoded)\n",
        "\n",
        "# end-to-end autoencoder\n",
        "vae = Model(x, x_decoded_mean)\n",
        "\n",
        "# encoder, from inputs to latent space\n",
        "encoder = Model(x, z_mean)\n",
        "\n",
        "# generator, from latent space to reconstructed inputs\n",
        "decoder_input = Input(shape=(latent_dim,))\n",
        "_h_decoded = decoder_h(decoder_input)\n",
        "_x_decoded_mean = decoder_mean(_h_decoded)\n",
        "generator = Model(decoder_input, _x_decoded_mean)\n",
        "\n",
        "def vae_loss(x, x_decoded_mean):\n",
        "    xent_loss = metrics.binary_crossentropy(x, x_decoded_mean)\n",
        "    kl_loss = - 0.5 * K.mean(1 + z_log_sigma - K.square(z_mean) - K.exp(z_log_sigma), axis=-1)\n",
        "    return xent_loss + kl_loss\n",
        "\n",
        "vae.compile(optimizer='rmsprop', loss=vae_loss)\n",
        "vae.summary()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4409: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (8, 6400)            0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (8, 3200)            20483200    input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (8, 15)              48015       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (8, 15)              48015       dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (8, 15)              0           dense_2[0][0]                    \n",
            "                                                                 dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 multiple             51200       lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 multiple             20486400    dense_4[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 41,116,830\n",
            "Trainable params: 41,116,830\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tO5vtbpJknm1",
        "colab_type": "code",
        "outputId": "6e641aac-42d4-4509-97ff-d6574e474358",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "history = vae.fit(x_train, x_train,\n",
        "        shuffle=True,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        validation_data=(x_test, x_test),\n",
        "        )\n",
        "print(history.history.keys())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/150\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "20000/20000 [==============================] - 100s 5ms/step - loss: 0.0026 - val_loss: 9.7693e-04\n",
            "Epoch 2/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7526e-04 - val_loss: 9.7484e-04\n",
            "Epoch 3/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7475e-04 - val_loss: 9.7429e-04\n",
            "Epoch 4/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7453e-04 - val_loss: 9.7576e-04\n",
            "Epoch 5/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7423e-04 - val_loss: 9.7563e-04\n",
            "Epoch 6/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7410e-04 - val_loss: 9.7385e-04\n",
            "Epoch 7/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7399e-04 - val_loss: 9.7408e-04\n",
            "Epoch 8/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7377e-04 - val_loss: 9.7385e-04\n",
            "Epoch 9/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7370e-04 - val_loss: 9.7291e-04\n",
            "Epoch 10/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7347e-04 - val_loss: 9.7441e-04\n",
            "Epoch 11/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7341e-04 - val_loss: 9.7422e-04\n",
            "Epoch 12/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7331e-04 - val_loss: 9.7279e-04\n",
            "Epoch 13/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7320e-04 - val_loss: 9.7376e-04\n",
            "Epoch 14/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7310e-04 - val_loss: 9.7423e-04\n",
            "Epoch 15/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7309e-04 - val_loss: 9.7350e-04\n",
            "Epoch 16/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7297e-04 - val_loss: 9.7243e-04\n",
            "Epoch 17/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7288e-04 - val_loss: 9.7417e-04\n",
            "Epoch 18/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7285e-04 - val_loss: 9.7249e-04\n",
            "Epoch 19/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7275e-04 - val_loss: 9.7167e-04\n",
            "Epoch 20/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7263e-04 - val_loss: 9.7291e-04\n",
            "Epoch 21/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7264e-04 - val_loss: 9.7277e-04\n",
            "Epoch 22/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7256e-04 - val_loss: 9.7259e-04\n",
            "Epoch 23/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7251e-04 - val_loss: 9.7347e-04\n",
            "Epoch 24/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7234e-04 - val_loss: 9.7218e-04\n",
            "Epoch 25/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7230e-04 - val_loss: 9.7369e-04\n",
            "Epoch 26/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7231e-04 - val_loss: 9.7203e-04\n",
            "Epoch 27/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7218e-04 - val_loss: 9.7336e-04\n",
            "Epoch 28/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7212e-04 - val_loss: 9.7197e-04\n",
            "Epoch 29/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7208e-04 - val_loss: 9.7317e-04\n",
            "Epoch 30/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7195e-04 - val_loss: 9.7165e-04\n",
            "Epoch 31/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7188e-04 - val_loss: 9.7139e-04\n",
            "Epoch 32/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7182e-04 - val_loss: 9.7209e-04\n",
            "Epoch 33/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7178e-04 - val_loss: 9.7247e-04\n",
            "Epoch 34/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7167e-04 - val_loss: 9.7165e-04\n",
            "Epoch 35/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7167e-04 - val_loss: 9.7204e-04\n",
            "Epoch 36/150\n",
            "20000/20000 [==============================] - 94s 5ms/step - loss: 9.7158e-04 - val_loss: 9.7313e-04\n",
            "Epoch 37/150\n",
            "20000/20000 [==============================] - 94s 5ms/step - loss: 9.7149e-04 - val_loss: 9.7156e-04\n",
            "Epoch 38/150\n",
            "20000/20000 [==============================] - 94s 5ms/step - loss: 9.7145e-04 - val_loss: 9.7111e-04\n",
            "Epoch 39/150\n",
            "20000/20000 [==============================] - 94s 5ms/step - loss: 9.7139e-04 - val_loss: 9.7166e-04\n",
            "Epoch 40/150\n",
            "20000/20000 [==============================] - 100s 5ms/step - loss: 9.7134e-04 - val_loss: 9.7239e-04\n",
            "Epoch 41/150\n",
            "20000/20000 [==============================] - 104s 5ms/step - loss: 9.7128e-04 - val_loss: 9.7242e-04\n",
            "Epoch 42/150\n",
            "20000/20000 [==============================] - 102s 5ms/step - loss: 9.7123e-04 - val_loss: 9.7151e-04\n",
            "Epoch 43/150\n",
            "20000/20000 [==============================] - 99s 5ms/step - loss: 9.7112e-04 - val_loss: 9.7210e-04\n",
            "Epoch 44/150\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 9.7106e-04 - val_loss: 9.7089e-04\n",
            "Epoch 45/150\n",
            "20000/20000 [==============================] - 96s 5ms/step - loss: 9.7098e-04 - val_loss: 9.7110e-04\n",
            "Epoch 46/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7102e-04 - val_loss: 9.7135e-04\n",
            "Epoch 47/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7092e-04 - val_loss: 9.7161e-04\n",
            "Epoch 48/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.7086e-04 - val_loss: 9.7087e-04\n",
            "Epoch 49/150\n",
            "20000/20000 [==============================] - 96s 5ms/step - loss: 9.7079e-04 - val_loss: 9.7061e-04\n",
            "Epoch 50/150\n",
            "20000/20000 [==============================] - 96s 5ms/step - loss: 9.7077e-04 - val_loss: 9.7048e-04\n",
            "Epoch 51/150\n",
            "20000/20000 [==============================] - 99s 5ms/step - loss: 9.7070e-04 - val_loss: 9.7065e-04\n",
            "Epoch 52/150\n",
            "20000/20000 [==============================] - 102s 5ms/step - loss: 9.7063e-04 - val_loss: 9.7138e-04\n",
            "Epoch 53/150\n",
            "20000/20000 [==============================] - 104s 5ms/step - loss: 9.7062e-04 - val_loss: 9.7156e-04\n",
            "Epoch 54/150\n",
            "20000/20000 [==============================] - 100s 5ms/step - loss: 9.7058e-04 - val_loss: 9.7095e-04\n",
            "Epoch 55/150\n",
            "20000/20000 [==============================] - 99s 5ms/step - loss: 9.7046e-04 - val_loss: 9.7059e-04\n",
            "Epoch 56/150\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 9.7045e-04 - val_loss: 9.7157e-04\n",
            "Epoch 57/150\n",
            "20000/20000 [==============================] - 99s 5ms/step - loss: 9.7036e-04 - val_loss: 9.7037e-04\n",
            "Epoch 58/150\n",
            "20000/20000 [==============================] - 100s 5ms/step - loss: 9.7032e-04 - val_loss: 9.7162e-04\n",
            "Epoch 59/150\n",
            "20000/20000 [==============================] - 100s 5ms/step - loss: 9.7034e-04 - val_loss: 9.7075e-04\n",
            "Epoch 60/150\n",
            "20000/20000 [==============================] - 99s 5ms/step - loss: 9.7024e-04 - val_loss: 9.7009e-04\n",
            "Epoch 61/150\n",
            "20000/20000 [==============================] - 98s 5ms/step - loss: 9.7018e-04 - val_loss: 9.7042e-04\n",
            "Epoch 62/150\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 9.7015e-04 - val_loss: 9.7087e-04\n",
            "Epoch 63/150\n",
            "20000/20000 [==============================] - 96s 5ms/step - loss: 9.7013e-04 - val_loss: 9.7057e-04\n",
            "Epoch 64/150\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 9.7004e-04 - val_loss: 9.7115e-04\n",
            "Epoch 65/150\n",
            "20000/20000 [==============================] - 97s 5ms/step - loss: 9.7001e-04 - val_loss: 9.7035e-04\n",
            "Epoch 66/150\n",
            "20000/20000 [==============================] - 96s 5ms/step - loss: 9.7001e-04 - val_loss: 9.7077e-04\n",
            "Epoch 67/150\n",
            "20000/20000 [==============================] - 95s 5ms/step - loss: 9.6998e-04 - val_loss: 9.7049e-04\n",
            "Epoch 68/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6987e-04 - val_loss: 9.7003e-04\n",
            "Epoch 69/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6991e-04 - val_loss: 9.7075e-04\n",
            "Epoch 70/150\n",
            "20000/20000 [==============================] - 94s 5ms/step - loss: 9.6987e-04 - val_loss: 9.7034e-04\n",
            "Epoch 71/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6978e-04 - val_loss: 9.6983e-04\n",
            "Epoch 72/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6980e-04 - val_loss: 9.6967e-04\n",
            "Epoch 73/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6973e-04 - val_loss: 9.7011e-04\n",
            "Epoch 74/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6965e-04 - val_loss: 9.7021e-04\n",
            "Epoch 75/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6964e-04 - val_loss: 9.6974e-04\n",
            "Epoch 76/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6960e-04 - val_loss: 9.7080e-04\n",
            "Epoch 77/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6958e-04 - val_loss: 9.7007e-04\n",
            "Epoch 78/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6954e-04 - val_loss: 9.6984e-04\n",
            "Epoch 79/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6947e-04 - val_loss: 9.6968e-04\n",
            "Epoch 80/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6948e-04 - val_loss: 9.6980e-04\n",
            "Epoch 81/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6944e-04 - val_loss: 9.6949e-04\n",
            "Epoch 82/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6940e-04 - val_loss: 9.6932e-04\n",
            "Epoch 83/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6939e-04 - val_loss: 9.6967e-04\n",
            "Epoch 84/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6933e-04 - val_loss: 9.6991e-04\n",
            "Epoch 85/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6934e-04 - val_loss: 9.6996e-04\n",
            "Epoch 86/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6927e-04 - val_loss: 9.6971e-04\n",
            "Epoch 87/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6923e-04 - val_loss: 9.6974e-04\n",
            "Epoch 88/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6919e-04 - val_loss: 9.6981e-04\n",
            "Epoch 89/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6920e-04 - val_loss: 9.7013e-04\n",
            "Epoch 90/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6919e-04 - val_loss: 9.6931e-04\n",
            "Epoch 91/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6913e-04 - val_loss: 9.6953e-04\n",
            "Epoch 92/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6911e-04 - val_loss: 9.6941e-04\n",
            "Epoch 93/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6907e-04 - val_loss: 9.6962e-04\n",
            "Epoch 94/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6903e-04 - val_loss: 9.6925e-04\n",
            "Epoch 95/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6904e-04 - val_loss: 9.6910e-04\n",
            "Epoch 96/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6897e-04 - val_loss: 9.6947e-04\n",
            "Epoch 97/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6899e-04 - val_loss: 9.6958e-04\n",
            "Epoch 98/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6895e-04 - val_loss: 9.6913e-04\n",
            "Epoch 99/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6890e-04 - val_loss: 9.6937e-04\n",
            "Epoch 100/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6890e-04 - val_loss: 9.6944e-04\n",
            "Epoch 101/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6887e-04 - val_loss: 9.6925e-04\n",
            "Epoch 102/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6884e-04 - val_loss: 9.6908e-04\n",
            "Epoch 103/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6879e-04 - val_loss: 9.7013e-04\n",
            "Epoch 104/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6882e-04 - val_loss: 9.6914e-04\n",
            "Epoch 105/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6878e-04 - val_loss: 9.6895e-04\n",
            "Epoch 106/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6878e-04 - val_loss: 9.6931e-04\n",
            "Epoch 107/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6875e-04 - val_loss: 9.6890e-04\n",
            "Epoch 108/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6873e-04 - val_loss: 9.6918e-04\n",
            "Epoch 109/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6874e-04 - val_loss: 9.6906e-04\n",
            "Epoch 110/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6871e-04 - val_loss: 9.6919e-04\n",
            "Epoch 111/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6870e-04 - val_loss: 9.6890e-04\n",
            "Epoch 112/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6866e-04 - val_loss: 9.6923e-04\n",
            "Epoch 113/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6864e-04 - val_loss: 9.6923e-04\n",
            "Epoch 114/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6864e-04 - val_loss: 9.6880e-04\n",
            "Epoch 115/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6860e-04 - val_loss: 9.6896e-04\n",
            "Epoch 116/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6859e-04 - val_loss: 9.6893e-04\n",
            "Epoch 117/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6856e-04 - val_loss: 9.6908e-04\n",
            "Epoch 118/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6857e-04 - val_loss: 9.6891e-04\n",
            "Epoch 119/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6856e-04 - val_loss: 9.6873e-04\n",
            "Epoch 120/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6855e-04 - val_loss: 9.6897e-04\n",
            "Epoch 121/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6851e-04 - val_loss: 9.6908e-04\n",
            "Epoch 122/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6855e-04 - val_loss: 9.6874e-04\n",
            "Epoch 123/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6856e-04 - val_loss: 9.6863e-04\n",
            "Epoch 124/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6850e-04 - val_loss: 9.6891e-04\n",
            "Epoch 125/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6850e-04 - val_loss: 9.6920e-04\n",
            "Epoch 126/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6849e-04 - val_loss: 9.6925e-04\n",
            "Epoch 127/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6849e-04 - val_loss: 9.6880e-04\n",
            "Epoch 128/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6848e-04 - val_loss: 9.6881e-04\n",
            "Epoch 129/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6850e-04 - val_loss: 9.6911e-04\n",
            "Epoch 130/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6852e-04 - val_loss: 9.6899e-04\n",
            "Epoch 131/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6851e-04 - val_loss: 9.6873e-04\n",
            "Epoch 132/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6847e-04 - val_loss: 9.6862e-04\n",
            "Epoch 133/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6846e-04 - val_loss: 9.6886e-04\n",
            "Epoch 134/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6847e-04 - val_loss: 9.6876e-04\n",
            "Epoch 135/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6843e-04 - val_loss: 9.6895e-04\n",
            "Epoch 136/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6846e-04 - val_loss: 9.6882e-04\n",
            "Epoch 137/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6847e-04 - val_loss: 9.6860e-04\n",
            "Epoch 138/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6846e-04 - val_loss: 9.6873e-04\n",
            "Epoch 139/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6846e-04 - val_loss: 9.6899e-04\n",
            "Epoch 140/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6848e-04 - val_loss: 9.6869e-04\n",
            "Epoch 141/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6847e-04 - val_loss: 9.6882e-04\n",
            "Epoch 142/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6847e-04 - val_loss: 9.6881e-04\n",
            "Epoch 143/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6848e-04 - val_loss: 9.6898e-04\n",
            "Epoch 144/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6850e-04 - val_loss: 9.6843e-04\n",
            "Epoch 145/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6849e-04 - val_loss: 9.6886e-04\n",
            "Epoch 146/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6847e-04 - val_loss: 9.6898e-04\n",
            "Epoch 147/150\n",
            "20000/20000 [==============================] - 93s 5ms/step - loss: 9.6853e-04 - val_loss: 9.6938e-04\n",
            "Epoch 148/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6849e-04 - val_loss: 9.6862e-04\n",
            "Epoch 149/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6848e-04 - val_loss: 9.6916e-04\n",
            "Epoch 150/150\n",
            "20000/20000 [==============================] - 92s 5ms/step - loss: 9.6851e-04 - val_loss: 9.6881e-04\n",
            "dict_keys(['val_loss', 'loss'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YGOtZm8s8AE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "outputId": "5f7f9d89-fc8e-4d26-b3f4-94bcd44ed926"
      },
      "source": [
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'], )\n",
        "#plt.axis(ymin=0.000968, ymax=0.00098)\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZsAAAEWCAYAAACwtjr+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvw/2JVibcgsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}